# Natural Language Processing Tutorial

This repo includes BERT and GPT implementations in Neural Language Processing (NLP).

## Installation

```shell script
$ git clone https://github.com/RichardYang88/Conv1D-FFN-Transform/
$ cd Conv1D-FFN-Transform/
$ sudo pip3 install -r requirements.txt
```

## GPT
[Improving Language Understanding by Generative Pre-Training](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)

<a target="_blank" href="https://mofanpy.com/static/results/nlp/gpt_structure.png" style="text-align: center">
<img src="https://mofanpy.com/static/results/nlp/gpt_structure.png" height="250px" alt="image">
</a>
<a target="_blank" href="https://mofanpy.com/static/results/nlp/gpt7_self_attention_line.png" style="text-align: center">
<img src="https://mofanpy.com/static/results/nlp/gpt7_self_attention_line.png" height="250px" alt="image">
</a>


## BERT
[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)

<a target="_blank" href="https://mofanpy.com/static/results/nlp/bert_gpt_comparison.png" style="text-align: center">
<img src="https://mofanpy.com/static/results/nlp/bert_gpt_comparison.png" height="250px" alt="image">
</a>
<a target="_blank" href="https://mofanpy.com/static/results/nlp/bert_self_mask4_self_attention_line.png" style="text-align: center">
<img src="https://mofanpy.com/static/results/nlp/bert_self_mask4_self_attention_line.png" height="250px" alt="image">
</a>

